{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf91688-f10c-42c4-a4d6-607c883827e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts.data_utils import get_connectome\n",
    "from scripts.classification_models import LogRegPCA\n",
    "# функции из scripts мы не меняли\n",
    "\n",
    "ihb_series_path = 'ihb.npy'\n",
    "ihb_labels_path = 'ihb.csv'\n",
    "\n",
    "X_ihb = np.load(ihb_series_path)\n",
    "Y_ihb = pd.read_csv(ihb_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c004cf3-6714-4952-ad7b-42f4214914ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ihb = get_connectome(X_ihb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16f6d09-7cd2-4470-a856-da45f4a52c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 12)\n",
      "Accuracy on train: 0.95\n"
     ]
    }
   ],
   "source": [
    "# идея заключается в том, чтобы обучать линейную регрессию только на датасете ihb, так как приватные данные соответсвуют ему\n",
    "\n",
    "logreg = LogRegPCA(pca=True)\n",
    "logreg.model.set_params(**{'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 100, 'C': 0.05})\n",
    "logreg.pca.set_params(**{'n_components': 12, 'svd_solver': 'full'})\n",
    "\n",
    "train_acc = logreg.model_training(X_ihb, Y_ihb.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e883ed8-b0dd-4730-be67-0c3f7379c548",
   "metadata": {},
   "source": [
    "Далее загружаем решение, как в бейзлайне"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69616688-450a-4d33-9d5e-f867f5988949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and weights \n",
    "\n",
    "pkl_filename = \"./model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(logreg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8ef207-f8ac-4113-aabe-d619409d2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create local environment same as Yandex Contest\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists('./data/ts_cut/HCPex/'):\n",
    "    os.makedirs('./data/ts_cut/HCPex/')\n",
    "\n",
    "np.save('./data/ts_cut/HCPex/predict.npy', np.concatenate([np.load(bnu_series_path.format(i)) for i in (1, 2)], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c81997-03d1-4c85-a1f4-49027a44ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 240, 419)\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# create script, which loads model, does all preprocessing and outputs solution.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from scripts.data_utils import get_connectome\n",
    "from scripts.classification_models import LogRegPCA\n",
    "\n",
    "X = np.load('./data/ts_cut/HCPex/predict.npy')\n",
    "print(X.shape)\n",
    "X = get_connectome(X)\n",
    "\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "y_pred = model.model_predict(X)\n",
    "print(y_pred)\n",
    "\n",
    "solution = pd.DataFrame(data=y_pred, columns=['prediction'])\n",
    "solution.to_csv('./solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab84c0be-3f5f-4281-8b17-bc2e280a5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the .zip to submit\n",
    "import zipfile\n",
    "import datetime\n",
    "\n",
    "# save source from previous cell into file\n",
    "# will produce the correct result only in case of running previous cell just before\n",
    "with open('run.py', 'w') as f_run:\n",
    "    f_run.write(_ih[-2])\n",
    "\n",
    "with open('run.sh', 'w') as f_run_sh:\n",
    "    f_run_sh.write('export PATH=/usr/conda/bin:$PATH\\npython run.py')\n",
    "\n",
    "with open('train.py', 'w') as f_run:\n",
    "    f_run.write('print(\"\\\\n\".join(map(str, range(100))))')\n",
    "\n",
    "with open('train.sh', 'w') as f_run_sh:\n",
    "    f_run_sh.write('export PATH=/usr/conda/bin:$PATH\\npython train.py')\n",
    "\n",
    "with open('Makefile', 'w') as f_makefile:\n",
    "    f_makefile.write('''all: build\n",
    "\n",
    "build:\n",
    "\t@echo 'starting....'\n",
    "\tbash train.sh\n",
    "run:\n",
    "\tbash run.sh\n",
    "train:\n",
    "\tbash train.sh\n",
    "''')\n",
    "\n",
    "submission_zip = zipfile.ZipFile(f\"submission-{datetime.datetime.now()}.zip\".replace(':', '-').replace(' ', '-'), \"w\")\n",
    "submission_zip.write('./Makefile', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('run.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('run.sh', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('train.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('train.sh', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('model.pkl', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('scripts', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('scripts/__init__.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('scripts/classification_models.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "submission_zip.write('scripts/data_utils.py', compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "submission_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a139942-3927-4636-bc94-f1b464928b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
